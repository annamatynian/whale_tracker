"""
Base Discovery Agent - –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –≤—Å–µ—Ö Discovery –∞–≥–µ–Ω—Ç–æ–≤ (–í–µ—Ä—Å–∏—è 2.1)

–°–æ–¥–µ—Ä–∂–∏—Ç –û–ë–©–£–Æ –ª–æ–≥–∏–∫—É:
- –£–õ–£–ß–®–ï–ù–ù–û–ï API –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ /dex/search
- –ï–¥–∏–Ω—É—é, –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—É—é –∫–æ–Ω—Å—Ç–∞–Ω—Ç—É –¥–ª—è –≤–æ–∑—Ä–∞—Å—Ç–∞ —Ç–æ–∫–µ–Ω–æ–≤
- –û–±—Ä–∞–±–æ—Ç–∫—É –æ—à–∏–±–æ–∫ –∏ –∞–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–µ –º–µ—Ç–æ–¥—ã

Author: Refactored architecture based on Gemini recommendations
"""

import requests
import logging
import subprocess
import time
import asyncio
from typing import Optional, List, Dict, Any, Tuple
from datetime import datetime
from pydantic import BaseModel, Field
from tenacity import retry, stop_after_attempt, wait_fixed
from abc import ABC, abstractmethod

# === –ë–ê–ó–û–í–´–ï –ö–û–ù–°–¢–ê–ù–¢–´ ===
CHAINS_TO_SCAN = ["ethereum", "solana", "base", "arbitrum"]

# --- –ö–õ–Æ–ß–ï–í–ê–Ø –ù–ê–°–¢–†–û–ô–ö–ê ---
# –û–ë–ù–û–í–õ–ï–ù–û –ü–û–î –ù–û–í–£–Æ –°–¢–†–ê–¢–ï–ì–ò–Æ: –∏—â–µ–º –∑—Ä–µ–ª—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–æ 3 –º–µ—Å—è—Ü–µ–≤ –≤–æ–∑—Ä–∞—Å—Ç–∞
# —Å –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏–µ–π $10M+ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—ã—Å–æ–∫—É—é –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å –∫–∞–∫ –ø—Ä–æ–∫—Å–∏)
# –≠—Ç–æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ API-–∑–∞–ø—Ä–æ—Å–µ –¥–ª—è –ø–µ—Ä–≤–∏—á–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.
MAX_AGE_FOR_SCAN_HOURS = 2160  # 3 –º–µ—Å—è—Ü–∞ (90 –¥–Ω–µ–π * 24 —á–∞—Å–∞)

# === –ë–ê–ó–û–í–ê–Ø –ú–û–î–ï–õ–¨ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ===
class TokenDiscoveryReport(BaseModel):
    pair_address: str = Field(..., description="–ê–¥—Ä–µ—Å —Ç–æ—Ä–≥–æ–≤–æ–π –ø–∞—Ä—ã –Ω–∞ DEX")
    chain_id: str = Field(..., description="ID —Å–µ—Ç–∏")
    base_token_address: str = Field(..., description="–ê–¥—Ä–µ—Å –±–∞–∑–æ–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞")
    base_token_symbol: str = Field(..., description="–°–∏–º–≤–æ–ª –±–∞–∑–æ–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞")
    base_token_name: str = Field(..., description="–ò–º—è –±–∞–∑–æ–≤–æ–≥–æ —Ç–æ–∫–µ–Ω–∞")
    liquidity_usd: float = Field(..., ge=0, description="–õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å –≤ USD")
    volume_h24: float = Field(..., ge=0, description="–û–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤ –∑–∞ 24 —á–∞—Å–∞ –≤ USD")
    price_usd: float = Field(..., description="–¢–µ–∫—É—â–∞—è —Ü–µ–Ω–∞ –≤ USD")
    price_change_h1: float = Field(..., description="–ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ü–µ–Ω—ã –∑–∞ 1 —á–∞—Å –≤ %")
    pair_created_at: datetime = Field(..., description="–í—Ä–µ–º—è —Å–æ–∑–¥–∞–Ω–∏—è –ø–∞—Ä—ã")
    age_minutes: float = Field(..., ge=0, description="–í–æ–∑—Ä–∞—Å—Ç –ø–∞—Ä—ã –≤ –º–∏–Ω—É—Ç–∞—Ö")
    discovery_score: int = Field(..., ge=0, le=100, description="–û—Ü–µ–Ω–∫–∞ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏")
    discovery_reason: str = Field(..., description="–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏")
    data_source: str = Field("DexScreener", description="–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö")
    discovery_timestamp: datetime = Field(default_factory=datetime.now)
    git_commit_hash: Optional[str] = Field(None)
    api_response_time_ms: Optional[float] = Field(None)
    processing_time_ms: Optional[float] = Field(None)

# === LOGGER SETUP (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ===
logger = logging.getLogger(__name__)
if not logger.handlers:
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# === –î–ï–ö–û–†–ê–¢–û–†–´ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ===
def track_api_cost(api_name: str, cost_units: int = 1):
    def decorator(func):
        def wrapper(*args, **kwargs):
            logger.debug(f"[CostTracker] Recording {cost_units} unit(s) for {api_name} API.")
            return func(*args, **kwargs)
        return wrapper
    return decorator

def rate_limit(api_name: str):
    def decorator(func):
        def wrapper(*args, **kwargs):
            logger.debug(f"[RateLimiter] Checking rate limit for {api_name}.")
            return func(*args, **kwargs)
        return wrapper
    return decorator

# === –£–¢–ò–õ–ò–¢–´ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ===
def get_current_git_hash() -> Optional[str]:
    try:
        result = subprocess.check_output(['git', 'rev-parse', '--short', 'HEAD'], stderr=subprocess.DEVNULL)
        return result.decode('ascii').strip()
    except Exception:
        return None

# === ‚òÖ‚òÖ‚òÖ –ò–ó–ú–ï–ù–ï–ù–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø API ‚òÖ‚òÖ‚òÖ ===
@rate_limit('dexscreener')
@track_api_cost('dexscreener', cost_units=1)
@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))
def fetch_pairs_for_chain(chain: str) -> Tuple[Optional[List[dict]], Optional[float]]:
    """
    –£–õ–£–ß–®–ï–ù–ù–ê–Ø —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ DexScreener.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–π —ç–Ω–¥–ø–æ–∏–Ω—Ç /dex/search —Å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–º –≤–æ–∑—Ä–∞—Å—Ç–æ–º.
    """
    # –°–æ–∑–¥–∞–µ–º —É–º–Ω—ã–π –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è –Ω–∞—à—É –∫–æ–Ω—Å—Ç–∞–Ω—Ç—É
    query = f"in:{chain} age < {MAX_AGE_FOR_SCAN_HOURS} hours sort by volume desc"
    
    url = f"https://api.dexscreener.com/latest/dex/search?q={query}"
    headers = {'User-Agent': 'crypto-multi-agent-system/1.0'}
    
    try:
        logger.debug(f"Searching pairs on {chain} with query: '{query}'")
        start_time = time.time()
        response = requests.get(url, headers=headers, timeout=15)
        
        # –£–ª—É—á—à–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
        response.raise_for_status() 
        
        data = response.json()
        response_time = (time.time() - start_time) * 1000
        
        # –í–∞–∂–Ω–æ: DexScreener –º–æ–∂–µ—Ç –≤–µ—Ä–Ω—É—Ç—å –ø—É—Å—Ç–æ–π 'pairs', –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
        found_pairs = data.get('pairs')
        if found_pairs is None: # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ null, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –Ω–∞ –ø—É—Å—Ç–æ—Ç—É
             logger.warning(f"DexScreener returned null pairs for chain {chain}. Response: {data}")
             return [], response_time

        logger.info(f"Found {len(found_pairs)} pairs on {chain} in {response_time:.1f}ms")
        return found_pairs, response_time

    except requests.exceptions.HTTPError as e:
        logger.error(f"HTTP Error for {chain}: {e.response.status_code} {e.response.reason}")
        return None, None
    except requests.exceptions.RequestException as e:
        logger.error(f"Request Error for {chain}: {e}")
        return None, None
    except ValueError as e: # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON
        logger.error(f"JSON Parse Error for {chain}: {e}")
        return None, None

# === –ë–ê–ó–û–í–´–ô –ö–õ–ê–°–° (—É–ª—É—á—à–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö) ===
class BaseDiscoveryAgent(ABC):
    def __init__(self):
        self.session_stats = { 'pairs_scanned': 0, 'reports_created': 0 }
        self.processed_addresses = set()
    
    @abstractmethod
    def _calculate_discovery_score(self, pair_data: Dict[str, Any], age_minutes: float) -> Tuple[int, str]:
        pass

    def discover_tokens(self) -> List[TokenDiscoveryReport]:
        logger.info(f"üöÄ Starting token discovery with {self.__class__.__name__}...")
        git_hash = get_current_git_hash()
        all_reports = []
        
        for chain in CHAINS_TO_SCAN:
            api_data, api_time = fetch_pairs_for_chain(chain)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ api_data –Ω–µ None (–≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ —Å–µ—Ç–∏)
            if api_data is None:
                continue

            for pair in api_data:
                try:
                    # –£–ª—É—á—à–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–∞–¥–µ–Ω–∏–π
                    if not pair or not pair.get('pairAddress') or pair.get('pairAddress') in self.processed_addresses:
                        continue
                    
                    self.processed_addresses.add(pair.get('pairAddress'))
                    self.session_stats['pairs_scanned'] += 1

                    created_at_ms = pair.get('pairCreatedAt')
                    if not created_at_ms:
                        continue # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞—Ç—ã —Å–æ–∑–¥–∞–Ω–∏—è
                    created_at = datetime.fromtimestamp(created_at_ms / 1000)
                    age_minutes = (datetime.now() - created_at).total_seconds() / 60
                    
                    score, reason = self._calculate_discovery_score(pair, age_minutes)

                    if score > 0:
                        # –ë–æ–ª–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
                        price_usd_str = pair.get('priceUsd', '0')
                        price_usd = float(price_usd_str) if price_usd_str else 0.0

                        report = TokenDiscoveryReport(
                            pair_address=pair['pairAddress'],
                            chain_id=pair['chainId'],
                            base_token_address=pair.get('baseToken', {}).get('address', 'N/A'),
                            base_token_symbol=pair.get('baseToken', {}).get('symbol', 'N/A'),
                            base_token_name=pair.get('baseToken', {}).get('name', 'N/A'),
                            liquidity_usd=pair.get('liquidity', {}).get('usd', 0),
                            volume_h24=pair.get('volume', {}).get('h24', 0),
                            price_usd=price_usd,
                            price_change_h1=pair.get('priceChange', {}).get('h1', 0),
                            pair_created_at=created_at,
                            age_minutes=age_minutes,
                            discovery_score=score,
                            discovery_reason=reason,
                            git_commit_hash=git_hash,
                            api_response_time_ms=api_time
                        )
                        all_reports.append(report)
                        self.session_stats['reports_created'] += 1

                except (ValueError, KeyError, TypeError) as e:
                    logger.warning(f"Skipping pair due to parsing error: {e} - Data: {pair.get('pairAddress')}")
                    continue
        
        logger.info(f"‚úÖ {self.__class__.__name__} complete: {self.session_stats['reports_created']} reports from {self.session_stats['pairs_scanned']} scanned.")
        return sorted(all_reports, key=lambda x: x.discovery_score, reverse=True)
    
    async def discover_tokens_async(self) -> List[TokenDiscoveryReport]:
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, self.discover_tokens)
