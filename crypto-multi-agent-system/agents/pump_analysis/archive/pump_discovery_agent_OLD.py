"""
Pump Discovery Agent - Specialized for Pump Detection

–ù–∞—Å–ª–µ–¥—É–µ—Ç –≤—Å—é —Ü–µ–Ω–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏–∑ –±–∞–∑–æ–≤–æ–≥–æ Discovery Agent
–∏ –¥–æ–±–∞–≤–ª—è–µ—Ç pump-specific –ª–æ–≥–∏–∫—É –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è.

–ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ—Ç:
- Multi-chain scanning
- Rate limiting & cost tracking decorators  
- Async/sync hybrid pattern
- Performance metrics & MLOps tracking
- Robust error handling

Author: Based on existing discovery_agent.py + Gemini corrected approach
"""

import asyncio
import time
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å—é —Ü–µ–Ω–Ω—É—é –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏–∑ –±–∞–∑–æ–≤–æ–≥–æ Discovery Agent
from ..discovery.discovery_agent import (
    fetch_pairs_for_chain,
    get_current_git_hash, 
    rate_limit,
    track_api_cost,
    CHAINS_TO_SCAN,
    logger
)

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—à–∏ pump-specific –º–æ–¥–µ–ª–∏
from .pump_models import (
    PumpIndicators, 
    PumpAnalysisReport,
    ApiUsageTracker,
    NarrativeType
)
from .realistic_scoring import RealisticScoringMatrix, RealisticPumpIndicators

# === PUMP-SPECIFIC CONFIGURATION ===
# –û—Å–Ω–æ–≤–∞–Ω–æ –Ω–∞ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–∏ –∏ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è—Ö –±–µ—Å–ø–ª–∞—Ç–Ω—ã—Ö API

PUMP_FILTERS = {
    'min_liquidity_usd': 5000,      # –°–Ω–∏–∂–µ–Ω –¥–ª—è —Ä–∞–Ω–Ω–µ–≥–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è
    'min_volume_24h': 1000,         # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
    'max_age_hours': 48,            # –û–∫–Ω–æ –¥–ª—è pump detection
    'max_dump_percent': -50,        # –ò–∑–±–µ–≥–∞–µ–º —É–∂–µ —É–ø–∞–≤—à–∏–µ —Ç–æ–∫–µ–Ω—ã
    'min_positive_momentum': 10     # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–æ—Å—Ç –¥–ª—è –∏–Ω—Ç–µ—Ä–µ—Å–∞
}

PUMP_SCORING_WEIGHTS_MVP = {
    'basic_screening': 40,          # –ü—Ä–æ—Ö–æ–¥–∏—Ç –±–∞–∑–æ–≤—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
    'early_detection_bonus': 20,    # –û—á–µ–Ω—å —Å–≤–µ–∂–∏–π —Ç–æ–∫–µ–Ω
    'liquidity_bonus': 15,          # –•–æ—Ä–æ—à–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
    'momentum_bonus': 15,           # –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–Ω–∞–º–∏–∫–∞
    'multi_chain_bonus': 10         # –ü—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–µ—Ç—è—Ö
}

class PumpDiscoveryAgent:
    """
    –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–≥–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ pump-–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤.
    –ù–∞—Å–ª–µ–¥—É–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –±–∞–∑–æ–≤–æ–≥–æ Discovery Agent.
    """
    
    def __init__(self):
        self.api_tracker = ApiUsageTracker()
        self.processed_addresses = set()
        self.session_stats = {
            'tokens_scanned': 0,
            'pump_candidates_found': 0,
            'api_calls_made': 0,
            'processing_start_time': None
        }
    
    def pump_initial_screening(self, pair_data: Dict[str, Any]) -> tuple[int, List[str]]:
        """
        Pump-specific screening —Å –¥–µ—Ç–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏—á–∏–Ω–∞–º–∏.
        –û—Å–Ω–æ–≤–∞–Ω –Ω–∞ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ DexScreener API.
        """
        reasons = []
        
        # –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        if not pair_data or not pair_data.get('liquidity'):
            return 0, ["Missing basic data"]
        
        liquidity_usd = pair_data.get('liquidity', {}).get('usd', 0)
        volume_24h = pair_data.get('volume', {}).get('h24', 0)
        price_change_24h = pair_data.get('priceChange', {}).get('h24', 0)
        price_change_1h = pair_data.get('priceChange', {}).get('h1', 0)
        
        # === –§–ò–õ–¨–¢–†–´ –ò–°–ö–õ–Æ–ß–ï–ù–ò–Ø (–∏–∑ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è) ===
        
        if liquidity_usd < PUMP_FILTERS['min_liquidity_usd']:
            return 0, [f"Low liquidity: ${liquidity_usd:,.0f} < ${PUMP_FILTERS['min_liquidity_usd']:,}"]
        
        if price_change_24h < PUMP_FILTERS['max_dump_percent']:
            return 0, [f"Already dumped: {price_change_24h:.1f}% < {PUMP_FILTERS['max_dump_percent']}%"]
        
        if volume_24h < PUMP_FILTERS['min_volume_24h']:
            return 0, [f"No trading activity: ${volume_24h:,.0f} < ${PUMP_FILTERS['min_volume_24h']:,}"]
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–æ–∑—Ä–∞—Å—Ç–∞
        created_at = pair_data.get('pairCreatedAt', 0)
        if created_at == 0:
            return 20, ["Unknown age - low priority"]
        
        age_hours = (time.time() - created_at/1000) / 3600
        if age_hours > PUMP_FILTERS['max_age_hours']:
            return 0, [f"Too old: {age_hours:.1f}h > {PUMP_FILTERS['max_age_hours']}h"]
        
        # === PUMP POTENTIAL SCORING ===
        
        score = PUMP_SCORING_WEIGHTS_MVP['basic_screening']  # –ë–∞–∑–æ–≤—ã–µ 40 –æ—á–∫–æ–≤
        reasons.append(f"Passed screening ({score}pts)")
        
        # –ë–æ–Ω—É—Å –∑–∞ —Ä–∞–Ω–Ω–µ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ
        if age_hours < 24:
            score += PUMP_SCORING_WEIGHTS_MVP['early_detection_bonus']
            reasons.append(f"Very fresh: {age_hours:.1f}h (+{PUMP_SCORING_WEIGHTS_MVP['early_detection_bonus']}pts)")
        
        # –ë–æ–Ω—É—Å –∑–∞ –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
        if liquidity_usd > 20000:
            score += PUMP_SCORING_WEIGHTS_MVP['liquidity_bonus']
            reasons.append(f"Good liquidity: ${liquidity_usd:,.0f} (+{PUMP_SCORING_WEIGHTS_MVP['liquidity_bonus']}pts)")
        
        # –ë–æ–Ω—É—Å –∑–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—É—é –¥–∏–Ω–∞–º–∏–∫—É
        if price_change_24h > PUMP_FILTERS['min_positive_momentum']:
            score += PUMP_SCORING_WEIGHTS_MVP['momentum_bonus']
            reasons.append(f"Positive momentum: +{price_change_24h:.1f}% (+{PUMP_SCORING_WEIGHTS_MVP['momentum_bonus']}pts)")
        
        return min(score, 90), reasons  # –†–µ–∑–µ—Ä–≤ 10 –æ—á–∫–æ–≤ –¥–ª—è premium –¥–∞–Ω–Ω—ã—Ö
    
    def create_pump_analysis_report(self, pair_data: Dict[str, Any], screening_score: int, 
                                  screening_reasons: List[str], git_hash: str) -> PumpAnalysisReport:
        """
        –°–æ–∑–¥–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∞ pump –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞.
        """
        created_at = datetime.fromtimestamp(pair_data.get('pairCreatedAt', 0) / 1000)
        age_hours = (time.time() - pair_data.get('pairCreatedAt', 0)/1000) / 3600
        
        # –ë–∞–∑–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –∏–∑ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        indicators = PumpIndicators(
            contract_address=pair_data['baseToken']['address'],
            
            # DexScreener –¥–∞–Ω–Ω—ã–µ
            liquidity_usd=pair_data['liquidity']['usd'],
            volume_24h=pair_data['volume']['h24'],
            age_hours=age_hours,
            
            # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ (–±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –¥—Ä—É–≥–∏–º–∏ –∞–≥–µ–Ω—Ç–∞–º–∏)
            pump_probability_score=screening_score,
            recommendation="NEEDS_FURTHER_ANALYSIS" if screening_score > 60 else "LOW_PRIORITY"
        )
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏
        next_steps = []
        if screening_score > 70:
            next_steps.extend([
                "üîç CoinGecko narrative analysis",
                "üõ°Ô∏è GoPlus security check", 
                "üì± Telegram social monitoring"
            ])
        elif screening_score > 50:
            next_steps.extend([
                "üîç CoinGecko narrative analysis",
                "üõ°Ô∏è GoPlus security check"
            ])
        else:
            next_steps.append("üìä Monitor for changes")
        
        return PumpAnalysisReport(
            contract_address=pair_data['baseToken']['address'],
            token_symbol=pair_data['baseToken']['symbol'],
            token_name=pair_data['baseToken']['name'],
            
            indicators=indicators,
            
            # Scoring breakdown
            narrative_score=0,  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ CoinGecko Agent
            security_score=0,   # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ Security Agent
            social_score=0,     # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ Social Agent
            
            reasoning=screening_reasons,
            red_flags=[],  # –ü–æ–∫–∞ –ø—É—Å—Ç–æ, –∑–∞–ø–æ–ª–Ω—è—Ç –¥—Ä—É–≥–∏–µ –∞–≥–µ–Ω—Ç—ã
            
            data_sources_used=["DexScreener"],
            api_calls_made=1,
            
            final_score=screening_score,
            confidence_level=0.6,  # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –Ω–∞ —ç—Ç–∞–ø–µ screening
            next_steps=next_steps
        )
    
    @rate_limit('dexscreener')
    @track_api_cost('dexscreener', cost_units=1)
    def discover_pump_candidates(self) -> List[PumpAnalysisReport]:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ pump –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤.
        –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –±–∞–∑–æ–≤–æ–≥–æ Discovery Agent.
        """
        self.session_stats['processing_start_time'] = time.time()
        logger.info("üéØ Starting PUMP-specific token discovery...")
        
        git_hash = get_current_git_hash()
        pump_candidates = []
        total_api_time = 0
        
        for chain in CHAINS_TO_SCAN:
            try:
                logger.debug(f"üîç Scanning {chain} for pump candidates...")
                
                api_data, api_time = fetch_pairs_for_chain(chain)
                if not api_data:
                    logger.warning(f"‚ùå No data from {chain}")
                    continue
                
                total_api_time += api_time or 0
                self.session_stats['api_calls_made'] += 1
                
                for pair in api_data:
                    if not pair or pair.get('pairAddress') in self.processed_addresses:
                        continue
                    
                    self.processed_addresses.add(pair.get('pairAddress'))
                    self.session_stats['tokens_scanned'] += 1
                    
                    # Pump-specific screening
                    screening_score, screening_reasons = self.pump_initial_screening(pair)
                    
                    if screening_score >= 50:  # –ü–æ—Ä–æ–≥ –¥–ª—è pump –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
                        pump_report = self.create_pump_analysis_report(
                            pair, screening_score, screening_reasons, git_hash
                        )
                        pump_candidates.append(pump_report)
                        self.session_stats['pump_candidates_found'] += 1
                        
                        logger.info(f"üéØ PUMP CANDIDATE: {pair['baseToken']['symbol']} "
                                  f"(Score: {screening_score}/100, Chain: {chain})")
                
            except Exception as e:
                logger.error(f"‚ùå Error scanning {chain}: {e}")
                continue
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        processing_time = time.time() - self.session_stats['processing_start_time']
        
        logger.info(
            f"‚úÖ Pump discovery complete: "
            f"{self.session_stats['pump_candidates_found']} candidates from "
            f"{self.session_stats['tokens_scanned']} scanned "
            f"({processing_time:.1f}s total, {total_api_time:.1f}ms API)"
        )
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ pump potential score
        return sorted(pump_candidates, key=lambda x: x.final_score, reverse=True)
    
    async def discover_pump_candidates_async(self) -> List[PumpAnalysisReport]:
        """
        Async wrapper –¥–ª—è pump discovery.
        –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω –∏–∑ –±–∞–∑–æ–≤–æ–≥–æ Discovery Agent.
        """
        logger.info("üîÑ Running pump discovery in async executor...")
        loop = asyncio.get_running_loop()
        return await loop.run_in_executor(None, self.discover_pump_candidates)
    
    def get_session_stats(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏"""
        return {
            **self.session_stats,
            'api_usage': self.api_tracker.model_dump(),
            'success_rate': (
                self.session_stats['pump_candidates_found'] / 
                max(self.session_stats['tokens_scanned'], 1) * 100
            )
        }

# === TESTING & STANDALONE USAGE ===

async def main():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Pump Discovery Agent"""
    print("üéØ Pump Discovery Agent - Testing Mode")
    print("=" * 50)
    
    agent = PumpDiscoveryAgent()
    
    try:
        pump_candidates = await agent.discover_pump_candidates_async()
        
        print(f"\nüìä Found {len(pump_candidates)} PUMP CANDIDATES")
        
        if not pump_candidates:
            print("\nüòî No pump candidates found in current scan.")
            return
        
        print("\nüöÄ === TOP PUMP CANDIDATES ===")
        for i, candidate in enumerate(pump_candidates[:5]):
            print(f"\n#{i+1}: {candidate.token_name} ({candidate.token_symbol})")
            print("-" * 40)
            print(f"   üéØ Pump Score: {candidate.final_score}/100")
            print(f"   üí∞ Liquidity: ${candidate.indicators.liquidity_usd:,.0f}")
            print(f"   üìä Volume 24h: ${candidate.indicators.volume_24h:,.0f}")
            print(f"   üïí Age: {candidate.indicators.age_hours:.1f} hours")
            print(f"   üí° Reasoning: {' | '.join(candidate.reasoning[:2])}")
            print(f"   üìã Next Steps: {', '.join(candidate.next_steps[:2])}")
        
        if len(pump_candidates) > 5:
            print(f"\n...and {len(pump_candidates) - 5} more candidates")
        
        # –ü–æ–∫–∞–∑–∞—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = agent.get_session_stats()
        print(f"\nüìà Session Stats:")
        print(f"   Tokens Scanned: {stats['tokens_scanned']}")
        print(f"   Pump Candidates: {stats['pump_candidates_found']}")
        print(f"   Success Rate: {stats['success_rate']:.1f}%")
        print(f"   API Calls: {stats['api_calls_made']}")
        
    except Exception as e:
        logger.error(f"‚ùå Error in pump discovery: {e}", exc_info=True)

if __name__ == "__main__":
    asyncio.run(main())
