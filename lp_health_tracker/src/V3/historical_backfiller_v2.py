"""
–û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è Historical Backfiller —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Storage Manager
"""
import asyncio
import logging
from datetime import datetime
from typing import List

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
from .hmm_market_data_collector import MarketDataPoint
from .v3_data_sources import V3GraphQLClient
from .historical_config import HISTORICAL_CONFIG, HistoricalDataConfig
from .storage_manager import create_storage_manager

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class HistoricalDataBackfillManager:
    """
    –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π Historical Data Backfiller —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Storage Manager.
    
    –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:
    - –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –µ–¥–∏–Ω—É—é —Å–∏—Å—Ç–µ–º—É —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
    - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç CSV –∏ SQLite backends
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –±–∞—Ç—á–µ–≤–∞—è –∑–∞–ø–∏—Å—å –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    -Áªü‰∏Ä API –¥–ª—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã
    """
    
    def __init__(self, config: HistoricalDataConfig):
        self.config = config
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Storage Manager
        self.storage = create_storage_manager()
        
        # HTTP –∏ GraphQL –∫–ª–∏–µ–Ω—Ç—ã
        self.http_session = None
        self.graph_client = V3GraphQLClient()
        
        # API endpoints
        self.coingecko_base_url = "https://api.coingecko.com/api/v3"
        self.binance_base_url = "https://api.binance.com"
        
        logger.info("Historical Data Backfill Manager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    async def __aenter__(self):
        """Async context manager entry."""
        import aiohttp
        self.http_session = aiohttp.ClientSession()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit."""
        await self.close_sessions()
    
    async def close_sessions(self):
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–∫—Ä—ã–≤–∞–µ—Ç –≤—Å–µ —Å–µ—Ç–µ–≤—ã–µ —Å–µ—Å—Å–∏–∏."""
        if self.http_session:
            await self.http_session.close()
        await self.graph_client.close()
        logger.info("–°–µ—Ç–µ–≤—ã–µ —Å–µ—Å—Å–∏–∏ –∑–∞–∫—Ä—ã—Ç—ã")
    
    # ... (–≤—Å–µ –º–µ—Ç–æ–¥—ã —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –æ—Å—Ç–∞—é—Ç—Å—è —Ç–µ–º–∏ –∂–µ)
    async def get_historical_eth_prices(self, start_date: datetime, end_date: datetime):
        """–ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ü–µ–Ω—ã ETH –æ—Ç CoinGecko."""
        start_timestamp = int(start_date.timestamp())
        end_timestamp = int(end_date.timestamp())
        
        url = f"{self.coingecko_base_url}/coins/ethereum/market_chart/range"
        params = {
            'vs_currency': 'usd',
            'from': start_timestamp,
            'to': end_timestamp
        }
        
        try:
            await asyncio.sleep(self.config.api_delay_seconds)
            
            async with self.http_session.get(url, params=params) as response:
                response.raise_for_status()
                data = await response.json()
                
                prices = {}
                for price_data in data.get('prices', []):
                    timestamp_ms, price = price_data
                    date_str = datetime.fromtimestamp(timestamp_ms / 1000).strftime('%Y-%m-%d')
                    prices[date_str] = float(price)
                
                logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(prices)} –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω ETH")
                return prices
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Ü–µ–Ω: {e}")
            return {}
    
    async def run_backfill_with_storage(self):
        """
        –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–±–æ—Ä–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö 
        —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Storage Manager.
        """
        logger.info("–ó–∞–ø—É—Å–∫ —Å–±–æ—Ä–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å Storage Manager...")
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç
        date_range = self.config.get_date_range()
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {len(date_range)} –¥–∞—Ç –æ—Ç {self.config.start_date} –¥–æ {self.config.end_date}")
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Ü–µ–Ω—ã –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
        start_date = date_range[0]
        end_date = date_range[-1]
        historical_prices = await self.get_historical_eth_prices(start_date, end_date)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –±–∞—Ç—á–∞–º–∏ –¥–ª—è –ª—É—á—à–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        batch_size = 100  # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –ø–æ 100 –∑–∞–ø–∏—Å–µ–π –∑–∞ —Ä–∞–∑
        data_batch = []
        previous_price = None
        processed_count = 0
        
        for target_date in date_range:
            date_str = target_date.strftime('%Y-%m-%d')
            
            # –ü–æ–ª—É—á–∞–µ–º —Ü–µ–Ω—É –¥–ª—è —ç—Ç–æ–π –¥–∞—Ç—ã
            eth_price = historical_prices.get(date_str, 0.0)
            if eth_price == 0.0:
                logger.warning(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ —Ü–µ–Ω–µ –¥–ª—è {date_str}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue
            
            try:
                # –°–æ–∑–¥–∞–µ–º —Ç–æ—á–∫—É –¥–∞–Ω–Ω—ã—Ö (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –ª–æ–≥–∏–∫—É)
                data_point = await self.create_historical_data_point(
                    target_date, eth_price, previous_price
                )
                data_batch.append(data_point)
                previous_price = eth_price
                processed_count += 1
                
                # –ö–æ–≥–¥–∞ –Ω–∞–±–∏—Ä–∞–µ–º –ø–æ–ª–Ω—ã–π batch - –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ storage
                if len(data_batch) >= batch_size:
                    self.storage.write_data_points(data_batch)
                    logger.info(f"–ó–∞–ø–∏—Å–∞–Ω batch: {len(data_batch)} –∑–∞–ø–∏—Å–µ–π. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count}/{len(date_range)}")
                    data_batch = []
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {date_str}: {e}")
                continue
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –¥–∞–Ω–Ω—ã–µ
        if data_batch:
            self.storage.write_data_points(data_batch)
            logger.info(f"–ó–∞–ø–∏—Å–∞–Ω —Ñ–∏–Ω–∞–ª—å–Ω—ã–π batch: {len(data_batch)} –∑–∞–ø–∏—Å–µ–π")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = self.storage.get_stats()
        logger.info(f"–°–±–æ—Ä –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∑–∞–≤–µ—Ä—à–µ–Ω. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats}")
        
        return processed_count
    
    async def create_historical_data_point(self, target_date: datetime, eth_price: float, previous_price):
        """–°–æ–∑–¥–∞–µ—Ç —Ç–æ—á–∫—É –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö."""
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–µ—Ç–æ–¥—ã –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ backfiller
        from .historical_backfiller import HistoricalDataBackfiller
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –º–µ—Ç–æ–¥–æ–≤
        temp_backfiller = HistoricalDataBackfiller(self.config)
        temp_backfiller.http_session = self.http_session
        
        return await temp_backfiller.create_historical_data_point(target_date, eth_price, previous_price)

# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞
async def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ historical backfiller."""
    logger.info("=== Historical Data Backfiller —Å Storage Manager ===")
    logger.info(f"Backend —Ö—Ä–∞–Ω–µ–Ω–∏—è: {HISTORICAL_CONFIG.csv_filename}")
    logger.info(f"–ü–µ—Ä–∏–æ–¥: {HISTORICAL_CONFIG.start_date} - {HISTORICAL_CONFIG.end_date}")
    
    async with HistoricalDataBackfillManager(HISTORICAL_CONFIG) as manager:
        processed_count = await manager.run_backfill_with_storage()
        
        print(f"\nüéâ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count} –∑–∞–ø–∏—Å–µ–π!")
        print("üìä –î–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ HMM –º–æ–¥–µ–ª—è—Ö")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º, –∫–∞–∫ –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è ML
        print("\nüí° –î–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ ML:")
        print("```python")
        print("import pandas as pd")
        print(f"df = pd.read_csv('{HISTORICAL_CONFIG.csv_filename}')")
        print("# –ì–æ—Ç–æ–≤–æ –¥–ª—è sklearn, numpy, etc.")
        print("```")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("–ü—Ä–æ–≥—Ä–∞–º–º–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C)")
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
